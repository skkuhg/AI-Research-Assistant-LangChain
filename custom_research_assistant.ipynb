{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ca2c8a5c",
      "metadata": {},
      "source": [
        "# üî¨ AI Research Assistant\n",
        "\n",
        "[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)\n",
        "[![LangChain](https://img.shields.io/badge/LangChain-0.1.0-green.svg)](https://github.com/langchain-ai/langchain)\n",
        "[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--3.5-orange.svg)](https://openai.com/)\n",
        "[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)\n",
        "\n",
        "## A Comprehensive Research Assistant Built with LangChain\n",
        "\n",
        "> **Transform your research workflow with AI-powered multi-source intelligence gathering, document processing, and analytics.**\n",
        "\n",
        "### üåü **Key Features**\n",
        "\n",
        "- üåê **Multi-source Research**: Seamlessly integrates Web search, arXiv, and Google Scholar\n",
        "- üß† **Intelligent Memory**: Contextual memory system for research history and user preferences\n",
        "- üìÑ **Document Processing**: Advanced vector storage and semantic search capabilities\n",
        "- üéØ **Interactive Interfaces**: Both notebook and web-based interfaces for flexible usage\n",
        "- üìä **Project Management**: Organize and track research projects with detailed reports\n",
        "- üìà **Data Export**: Export research data in JSON, CSV, and Excel formats\n",
        "- üìâ **Analytics Dashboard**: Visualize research trends, costs, and productivity metrics\n",
        "- üí∞ **Cost Tracking**: Monitor and optimize API usage and expenses\n",
        "- üîç **Quality Analysis**: Automated assessment of research completeness and reliability\n",
        "\n",
        "### üöÄ **Quick Start**\n",
        "\n",
        "1. **üì¶ Install Dependencies**: Run the installation cell below\n",
        "2. **üîê Set API Key**: Configure your OpenAI API key\n",
        "3. **‚öôÔ∏è Initialize Assistant**: Set up the research assistant\n",
        "4. **üéØ Start Researching**: Use the various research functions\n",
        "\n",
        "### üìñ **Table of Contents**\n",
        "\n",
        "- [Installation](#installation)\n",
        "- [Configuration](#configuration)\n",
        "- [Core Components](#core-components)\n",
        "- [Usage Examples](#usage-examples)\n",
        "- [Advanced Features](#advanced-features)\n",
        "- [Analytics & Visualization](#analytics--visualization)\n",
        "- [Contributing](#contributing)\n",
        "- [License](#license)\n",
        "\n",
        "---\n",
        "\n",
        "> **‚ö†Ô∏è Important**: This notebook requires an OpenAI API key. Make sure to set up your API key before running the cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f020fdc1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ Installation\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import platform\n",
        "\n",
        "def check_python_version():\n",
        "    \"\"\"Check if Python version is compatible\"\"\"\n",
        "    version = sys.version_info\n",
        "    if version.major >= 3 and version.minor >= 8:\n",
        "        print(f\"‚úÖ Python {version.major}.{version.minor}.{version.micro} is compatible\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"‚ùå Python {version.major}.{version.minor}.{version.micro} is not compatible\")\n",
        "        print(\"üîÑ Please upgrade to Python 3.8 or higher\")\n",
        "        return False\n",
        "\n",
        "def install_requirements():\n",
        "    \"\"\"Install all required packages from requirements.txt\"\"\"\n",
        "    try:\n",
        "        print(\"üì¶ Installing dependencies...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\", \"--quiet\"])\n",
        "        print(\"‚úÖ All dependencies installed successfully!\")\n",
        "        return True\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"‚ùå Error installing dependencies: {e}\")\n",
        "        print(\"üí° Try running: pip install -r requirements.txt\")\n",
        "        return False\n",
        "\n",
        "def display_system_info():\n",
        "    \"\"\"Display system information\"\"\"\n",
        "    print(f\"üñ•Ô∏è  System: {platform.system()} {platform.release()}\")\n",
        "    print(f\"üêç Python: {sys.version.split()[0]}\")\n",
        "    print(f\"üìç Platform: {platform.platform()}\")\n",
        "\n",
        "# Check system compatibility\n",
        "print(\"üîç System Compatibility Check\")\n",
        "print(\"=\" * 40)\n",
        "display_system_info()\n",
        "python_ok = check_python_version()\n",
        "\n",
        "if python_ok:\n",
        "    print(\"\\nüìã Required Packages:\")\n",
        "    try:\n",
        "        with open(\"requirements.txt\", \"r\") as f:\n",
        "            requirements = f.read().strip().split(\"\\n\")\n",
        "            for req in requirements:\n",
        "                if req.strip() and not req.startswith(\"#\"):\n",
        "                    print(f\"  üìå {req}\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"‚ö†Ô∏è  requirements.txt file not found\")\n",
        "    \n",
        "    print(\"\\nüöÄ Ready to install dependencies!\")\n",
        "    print(\"üí° Uncomment the line below to install all packages:\")\n",
        "    print(\"   # install_requirements()\")\n",
        "else:\n",
        "    print(\"‚ùå Please upgrade Python before proceeding\")\n",
        "\n",
        "# Uncomment the line below to install dependencies\n",
        "# install_requirements()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22619155",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List, Dict, Any, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# LangChain imports\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Additional imports for research capabilities\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import arxiv\n",
        "from scholarly import scholarly\n",
        "import tiktoken\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "print(\"üöÄ All imports successful!\")\n",
        "print(\"üìä Setting up plotting style...\")\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e239a2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîê API Key Configuration\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def setup_api_key():\n",
        "    \"\"\"Setup OpenAI API key with multiple methods\"\"\"\n",
        "    \n",
        "    print(\"üîê OpenAI API Key Setup\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Method 1: Environment variable (most secure)\n",
        "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    \n",
        "    if api_key:\n",
        "        print(\"‚úÖ API key found in environment variables\")\n",
        "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
        "        return api_key\n",
        "    \n",
        "    # Method 2: .env file (recommended for development)\n",
        "    env_file = Path(\".env\")\n",
        "    if env_file.exists():\n",
        "        print(\"üìÑ Found .env file, loading...\")\n",
        "        try:\n",
        "            from dotenv import load_dotenv\n",
        "            load_dotenv()\n",
        "            api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "            if api_key:\n",
        "                print(\"‚úÖ API key loaded from .env file\")\n",
        "                return api_key\n",
        "        except ImportError:\n",
        "            print(\"‚ö†Ô∏è  python-dotenv not installed, skipping .env file\")\n",
        "    \n",
        "    # Method 3: Manual input (for testing only)\n",
        "    print(\"‚ö†Ô∏è  No API key found in environment variables or .env file\")\n",
        "    print(\"\\nüîß Setup Options:\")\n",
        "    print(\"   1. üåç Environment Variable (Recommended):\")\n",
        "    print(\"      export OPENAI_API_KEY='your_api_key_here'\")\n",
        "    print(\"   2. üìÑ .env File (Development):\")\n",
        "    print(\"      Create .env file with: OPENAI_API_KEY=your_api_key_here\")\n",
        "    print(\"   3. üîí Manual Input (Testing Only):\")\n",
        "    print(\"      Uncomment and modify the line below\")\n",
        "    print(\"      # api_key = 'your_api_key_here'\")\n",
        "    \n",
        "    return None\n",
        "\n",
        "def setup_langsmith_tracing():\n",
        "    \"\"\"Setup optional LangSmith tracing for debugging\"\"\"\n",
        "    \n",
        "    langsmith_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
        "    \n",
        "    if langsmith_key:\n",
        "        print(\"\\nüîç LangSmith Configuration Found\")\n",
        "        print(\"=\" * 30)\n",
        "        os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "        os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\", \"ai-research-assistant\")\n",
        "        print(\"‚úÖ LangSmith tracing enabled for debugging\")\n",
        "        print(f\"üìä Project: {os.environ['LANGCHAIN_PROJECT']}\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"\\nüí° LangSmith tracing not configured (optional)\")\n",
        "        return False\n",
        "\n",
        "# Setup API key\n",
        "OPENAI_API_KEY = setup_api_key()\n",
        "\n",
        "# Setup optional tracing\n",
        "setup_langsmith_tracing()\n",
        "\n",
        "# Final status\n",
        "print(\"\\nüéØ Configuration Status:\")\n",
        "print(\"=\" * 25)\n",
        "if OPENAI_API_KEY:\n",
        "    print(\"‚úÖ OpenAI API: Configured\")\n",
        "    print(\"üöÄ Ready to proceed!\")\n",
        "else:\n",
        "    print(\"‚ùå OpenAI API: Not configured\")\n",
        "    print(\"‚ö†Ô∏è  Please set up your API key before continuing\")\n",
        "    print(\"üîó Get your API key: https://platform.openai.com/api-keys\")\n",
        "\n",
        "# Security reminder\n",
        "print(\"\\nüîí Security Reminder:\")\n",
        "print(\"   ‚Ä¢ Never commit API keys to version control\")\n",
        "print(\"   ‚Ä¢ Use environment variables in production\")\n",
        "print(\"   ‚Ä¢ Monitor your API usage regularly\")\n",
        "print(\"   ‚Ä¢ Keep your API keys secure and private\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77e7d8a5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üß† Research Memory System\n",
        "\n",
        "class ResearchMemory:\n",
        "    \"\"\"\n",
        "    Intelligent memory system for research preferences and history\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.preferences = {\n",
        "            'summary_style': 'comprehensive',\n",
        "            'preferred_sources': ['academic', 'web', 'news'],\n",
        "            'max_results': 5,\n",
        "            'include_analysis': True\n",
        "        }\n",
        "        self.research_history = []\n",
        "        self.session_stats = {\n",
        "            'queries_conducted': 0,\n",
        "            'total_tokens': 0,\n",
        "            'total_cost': 0.0,\n",
        "            'session_start': datetime.now()\n",
        "        }\n",
        "        self.context_memory = ConversationBufferMemory(\n",
        "            memory_key=\"chat_history\",\n",
        "            return_messages=True\n",
        "        )\n",
        "    \n",
        "    def update_preferences(self, key: str, value: Any):\n",
        "        \"\"\"Update user preferences\"\"\"\n",
        "        self.preferences[key] = value\n",
        "        print(f\"‚úÖ Updated {key} to {value}\")\n",
        "    \n",
        "    def add_research_entry(self, query: str, result: Dict, cost: float = 0.0):\n",
        "        \"\"\"Add a research entry to history\"\"\"\n",
        "        entry = {\n",
        "            'timestamp': datetime.now(),\n",
        "            'query': query,\n",
        "            'result': result,\n",
        "            'cost': cost,\n",
        "            'tokens': result.get('tokens_used', 0)\n",
        "        }\n",
        "        self.research_history.append(entry)\n",
        "        \n",
        "        # Update session stats\n",
        "        self.session_stats['queries_conducted'] += 1\n",
        "        self.session_stats['total_tokens'] += result.get('tokens_used', 0)\n",
        "        self.session_stats['total_cost'] += cost\n",
        "    \n",
        "    def get_recent_context(self, limit: int = 3) -> str:\n",
        "        \"\"\"Get recent research context for better continuity\"\"\"\n",
        "        if not self.research_history:\n",
        "            return \"\"\n",
        "        \n",
        "        recent_entries = self.research_history[-limit:]\n",
        "        context = \"Recent research context:\\n\"\n",
        "        for entry in recent_entries:\n",
        "            context += f\"- {entry['query'][:100]}...\\n\"\n",
        "        return context\n",
        "    \n",
        "    def get_session_summary(self) -> Dict:\n",
        "        \"\"\"Get current session summary\"\"\"\n",
        "        duration = datetime.now() - self.session_stats['session_start']\n",
        "        return {\n",
        "            **self.session_stats,\n",
        "            'session_duration': str(duration).split('.')[0],\n",
        "            'avg_cost_per_query': self.session_stats['total_cost'] / max(1, self.session_stats['queries_conducted'])\n",
        "        }\n",
        "\n",
        "# Initialize research memory\n",
        "research_memory = ResearchMemory()\n",
        "print(\"üß† Research memory system initialized!\")\n",
        "print(f\"üìä Current preferences: {research_memory.preferences}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be5520df",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìÑ Document Processing System\n",
        "\n",
        "class DocumentProcessor:\n",
        "    \"\"\"\n",
        "    Advanced document processing with vector storage and semantic search\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, api_key: str):\n",
        "        self.embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200\n",
        "        )\n",
        "        self.vectorstore = None\n",
        "        self.documents = []\n",
        "        \n",
        "    def process_documents(self, texts: List[str], metadata: List[Dict] = None):\n",
        "        \"\"\"Process and store documents in vector database\"\"\"\n",
        "        if metadata is None:\n",
        "            metadata = [{}] * len(texts)\n",
        "            \n",
        "        all_chunks = []\n",
        "        all_metadata = []\n",
        "        \n",
        "        for i, text in enumerate(texts):\n",
        "            chunks = self.text_splitter.split_text(text)\n",
        "            all_chunks.extend(chunks)\n",
        "            # Add metadata for each chunk\n",
        "            chunk_metadata = [\n",
        "                {**metadata[i], 'chunk_index': j, 'source_index': i}\n",
        "                for j in range(len(chunks))\n",
        "            ]\n",
        "            all_metadata.extend(chunk_metadata)\n",
        "        \n",
        "        # Create or update vector store\n",
        "        if self.vectorstore is None:\n",
        "            self.vectorstore = Chroma.from_texts(\n",
        "                all_chunks, \n",
        "                self.embeddings,\n",
        "                metadatas=all_metadata\n",
        "            )\n",
        "        else:\n",
        "            self.vectorstore.add_texts(all_chunks, metadatas=all_metadata)\n",
        "        \n",
        "        self.documents.extend(list(zip(texts, metadata)))\n",
        "        print(f\"üìÑ Processed {len(texts)} documents into {len(all_chunks)} chunks\")\n",
        "    \n",
        "    def add_document_from_url(self, url: str) -> str:\n",
        "        \"\"\"Add document from URL\"\"\"\n",
        "        try:\n",
        "            loader = WebBaseLoader(url)\n",
        "            docs = loader.load()\n",
        "            \n",
        "            if docs:\n",
        "                texts = [doc.page_content for doc in docs]\n",
        "                metadata = [{'source': url, 'type': 'web'}]\n",
        "                self.process_documents(texts, metadata)\n",
        "                return f\"‚úÖ Successfully added document from {url}\"\n",
        "            else:\n",
        "                return f\"‚ùå Could not load content from {url}\"\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Error loading document from {url}: {str(e)}\"\n",
        "    \n",
        "    def query_documents(self, query: str, k: int = 3) -> str:\n",
        "        \"\"\"Query documents using semantic search\"\"\"\n",
        "        if self.vectorstore is None:\n",
        "            return \"‚ùå No documents loaded. Please add documents first.\"\n",
        "        \n",
        "        try:\n",
        "            # Perform similarity search\n",
        "            docs = self.vectorstore.similarity_search(query, k=k)\n",
        "            \n",
        "            if not docs:\n",
        "                return \"‚ùå No relevant documents found.\"\n",
        "            \n",
        "            # Format results\n",
        "            results = []\n",
        "            for i, doc in enumerate(docs, 1):\n",
        "                metadata = doc.metadata\n",
        "                source = metadata.get('source', 'Unknown')\n",
        "                results.append(f\"**Result {i}** (Source: {source}):\\n{doc.page_content}\\n\")\n",
        "            \n",
        "            return \"\\n\".join(results)\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Error querying documents: {str(e)}\"\n",
        "    \n",
        "    def get_document_stats(self) -> Dict:\n",
        "        \"\"\"Get statistics about loaded documents\"\"\"\n",
        "        total_chunks = 0\n",
        "        if self.vectorstore is not None:\n",
        "            # This is an approximation as Chroma doesn't provide direct count\n",
        "            total_chunks = len(self.vectorstore.get()['ids'])\n",
        "        \n",
        "        return {\n",
        "            'total_documents': len(self.documents),\n",
        "            'total_chunks': total_chunks,\n",
        "            'has_vectorstore': self.vectorstore is not None\n",
        "        }\n",
        "\n",
        "# Initialize document processor (will be created when API key is available)\n",
        "doc_processor = None\n",
        "if OPENAI_API_KEY:\n",
        "    doc_processor = DocumentProcessor(OPENAI_API_KEY)\n",
        "    print(\"üìÑ Document processor initialized!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Document processor not initialized - API key required\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04f7a6ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üî¨ Main Research Assistant Class\n",
        "\n",
        "class ResearchAssistant:\n",
        "    \"\"\"\n",
        "    Comprehensive AI Research Assistant with multi-source capabilities\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, api_key: str):\n",
        "        self.api_key = api_key\n",
        "        self.llm = ChatOpenAI(\n",
        "            temperature=0.3,\n",
        "            openai_api_key=api_key,\n",
        "            model_name=\"gpt-3.5-turbo\"\n",
        "        )\n",
        "        self.memory = research_memory\n",
        "        self.doc_processor = doc_processor\n",
        "        self.search_wrapper = DuckDuckGoSearchAPIWrapper()\n",
        "        \n",
        "        # Initialize cost tracking\n",
        "        self.encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "        \n",
        "        # Research prompt template\n",
        "        self.research_prompt = PromptTemplate(\n",
        "            input_variables=[\"query\", \"context\", \"style\"],\n",
        "            template=\"\"\"\n",
        "            You are an expert research assistant. Conduct comprehensive research on the following query.\n",
        "            \n",
        "            Query: {query}\n",
        "            \n",
        "            Context from previous research: {context}\n",
        "            \n",
        "            Research Style: {style}\n",
        "            \n",
        "            Please provide:\n",
        "            1. A comprehensive summary of the topic\n",
        "            2. Key findings and insights\n",
        "            3. Current trends and developments\n",
        "            4. Reliable sources and references\n",
        "            5. Practical applications or implications\n",
        "            \n",
        "            Make sure to be thorough, accurate, and cite your sources when possible.\n",
        "            \"\"\"\n",
        "        )\n",
        "        \n",
        "        self.research_chain = LLMChain(\n",
        "            llm=self.llm,\n",
        "            prompt=self.research_prompt,\n",
        "            memory=self.memory.context_memory\n",
        "        )\n",
        "        \n",
        "        print(\"üî¨ Research Assistant initialized successfully!\")\n",
        "    \n",
        "    def estimate_cost(self, text: str, model: str = \"gpt-3.5-turbo\") -> float:\n",
        "        \"\"\"Estimate the cost of a text processing request\"\"\"\n",
        "        tokens = len(self.encoding.encode(text))\n",
        "        \n",
        "        # Pricing as of 2024 (approximate)\n",
        "        if model == \"gpt-3.5-turbo\":\n",
        "            cost_per_token = 0.0015 / 1000  # $0.0015 per 1K tokens\n",
        "        else:\n",
        "            cost_per_token = 0.002 / 1000   # Default fallback\n",
        "        \n",
        "        return tokens * cost_per_token\n",
        "    \n",
        "    def web_search(self, query: str, num_results: int = 5) -> List[Dict]:\n",
        "        \"\"\"Perform web search using DuckDuckGo\"\"\"\n",
        "        try:\n",
        "            search_results = self.search_wrapper.run(query)\n",
        "            \n",
        "            # Parse results (simplified)\n",
        "            results = []\n",
        "            if search_results:\n",
        "                # Split by common separators and take first few results\n",
        "                raw_results = search_results.split('\\n')[:num_results]\n",
        "                for i, result in enumerate(raw_results):\n",
        "                    if result.strip():\n",
        "                        results.append({\n",
        "                            'title': f\"Search Result {i+1}\",\n",
        "                            'content': result.strip(),\n",
        "                            'source': 'web_search'\n",
        "                        })\n",
        "            \n",
        "            return results\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Web search error: {str(e)}\")\n",
        "            return []\n",
        "    \n",
        "    def arxiv_search(self, query: str, max_results: int = 3) -> List[Dict]:\n",
        "        \"\"\"Search arXiv for academic papers\"\"\"\n",
        "        try:\n",
        "            client = arxiv.Client()\n",
        "            search = arxiv.Search(\n",
        "                query=query,\n",
        "                max_results=max_results,\n",
        "                sort_by=arxiv.SortCriterion.SubmittedDate\n",
        "            )\n",
        "            \n",
        "            results = []\n",
        "            for paper in client.results(search):\n",
        "                results.append({\n",
        "                    'title': paper.title,\n",
        "                    'summary': paper.summary[:500] + \"...\" if len(paper.summary) > 500 else paper.summary,\n",
        "                    'authors': [author.name for author in paper.authors],\n",
        "                    'url': paper.entry_id,\n",
        "                    'source': 'arxiv'\n",
        "                })\n",
        "            \n",
        "            return results\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è arXiv search error: {str(e)}\")\n",
        "            return []\n",
        "    \n",
        "    def research(self, query: str, include_analysis: bool = True) -> Dict:\n",
        "        \"\"\"\n",
        "        Main research function that combines multiple sources\n",
        "        \"\"\"\n",
        "        start_time = datetime.now()\n",
        "        \n",
        "        try:\n",
        "            # Get context from memory\n",
        "            context = self.memory.get_recent_context()\n",
        "            style = self.memory.preferences['summary_style']\n",
        "            \n",
        "            # Gather information from multiple sources\n",
        "            print(f\"üîç Searching for: {query}\")\n",
        "            \n",
        "            # Web search\n",
        "            web_results = self.web_search(query, 3)\n",
        "            print(f\"üåê Found {len(web_results)} web results\")\n",
        "            \n",
        "            # Academic search\n",
        "            arxiv_results = self.arxiv_search(query, 2)\n",
        "            print(f\"üìö Found {len(arxiv_results)} academic papers\")\n",
        "            \n",
        "            # Combine all source information\n",
        "            all_sources = []\n",
        "            source_content = \"\"\n",
        "            \n",
        "            for result in web_results + arxiv_results:\n",
        "                source_info = f\"Source: {result['source']}\\n\"\n",
        "                if 'title' in result:\n",
        "                    source_info += f\"Title: {result['title']}\\n\"\n",
        "                if 'content' in result:\n",
        "                    source_info += f\"Content: {result['content']}\\n\"\n",
        "                elif 'summary' in result:\n",
        "                    source_info += f\"Summary: {result['summary']}\\n\"\n",
        "                \n",
        "                source_content += source_info + \"\\n---\\n\"\n",
        "                all_sources.append(result.get('title', result.get('content', 'Unknown source')))\n",
        "            \n",
        "            # Generate comprehensive research summary\n",
        "            enhanced_query = f\"{query}\\n\\nAvailable information:\\n{source_content}\"\n",
        "            \n",
        "            # Estimate cost\n",
        "            estimated_cost = self.estimate_cost(enhanced_query)\n",
        "            \n",
        "            # Generate research findings\n",
        "            findings = self.research_chain.run(\n",
        "                query=enhanced_query,\n",
        "                context=context,\n",
        "                style=style\n",
        "            )\n",
        "            \n",
        "            # Calculate actual tokens used (approximation)\n",
        "            total_tokens = len(self.encoding.encode(enhanced_query + findings))\n",
        "            actual_cost = self.estimate_cost(enhanced_query + findings)\n",
        "            \n",
        "            # Prepare result\n",
        "            result = {\n",
        "                'query': query,\n",
        "                'findings': findings,\n",
        "                'sources': all_sources,\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'tokens_used': total_tokens,\n",
        "                'cost': actual_cost,\n",
        "                'processing_time': (datetime.now() - start_time).total_seconds()\n",
        "            }\n",
        "            \n",
        "            # Add analysis if requested\n",
        "            if include_analysis:\n",
        "                result['analysis'] = self.analyze_research_quality(findings)\n",
        "            \n",
        "            # Update memory\n",
        "            self.memory.add_research_entry(query, result, actual_cost)\n",
        "            \n",
        "            return result\n",
        "            \n",
        "        except Exception as e:\n",
        "            error_result = {\n",
        "                'query': query,\n",
        "                'error': True,\n",
        "                'findings': f\"Research failed: {str(e)}\",\n",
        "                'sources': [],\n",
        "                'timestamp': datetime.now().isoformat(),\n",
        "                'tokens_used': 0,\n",
        "                'cost': 0.0\n",
        "            }\n",
        "            return error_result\n",
        "    \n",
        "    def analyze_research_quality(self, findings: str) -> Dict:\n",
        "        \"\"\"Analyze the quality and completeness of research findings\"\"\"\n",
        "        analysis = {\n",
        "            'word_count': len(findings.split()),\n",
        "            'has_citations': '(' in findings or '[' in findings,\n",
        "            'confidence_indicators': [],\n",
        "            'completeness_score': 0.0\n",
        "        }\n",
        "        \n",
        "        # Look for confidence indicators\n",
        "        confidence_words = ['studies show', 'research indicates', 'evidence suggests', \n",
        "                           'according to', 'data reveals', 'analysis confirms']\n",
        "        \n",
        "        for word in confidence_words:\n",
        "            if word.lower() in findings.lower():\n",
        "                analysis['confidence_indicators'].append(word)\n",
        "        \n",
        "        # Calculate completeness score\n",
        "        score = 0.0\n",
        "        if analysis['word_count'] > 100:\n",
        "            score += 0.3\n",
        "        if analysis['has_citations']:\n",
        "            score += 0.3\n",
        "        if len(analysis['confidence_indicators']) > 0:\n",
        "            score += 0.2\n",
        "        if len(findings.split('.')) > 5:  # Multiple sentences\n",
        "            score += 0.2\n",
        "        \n",
        "        analysis['completeness_score'] = min(score, 1.0)\n",
        "        \n",
        "        return analysis\n",
        "\n",
        "# Initialize the research assistant\n",
        "research_assistant = None\n",
        "if OPENAI_API_KEY:\n",
        "    research_assistant = ResearchAssistant(OPENAI_API_KEY)\n",
        "    print(\"üéâ Research Assistant ready for use!\")\n",
        "else:\n",
        "    print(\"‚ùå Cannot initialize Research Assistant - API key required\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b8d049e",
      "metadata": {},
      "source": [
        "## üéØ Usage Examples and Demonstrations\n",
        "\n",
        "Now that we have our Research Assistant set up, let's explore its capabilities with practical examples.\n",
        "\n",
        "### üìã **Prerequisites Checklist**\n",
        "\n",
        "Before running the examples, ensure you have:\n",
        "- ‚úÖ Installed all dependencies\n",
        "- ‚úÖ Configured your OpenAI API key\n",
        "- ‚úÖ System status check passed\n",
        "- ‚úÖ All components initialized successfully\n",
        "\n",
        "### üîß **System Status Check**\n",
        "\n",
        "Run the cell below to verify that all components are properly initialized and ready to use.\n",
        "\n",
        "> **üí° Tip**: If any components show as \"Not Ready\", please review the setup cells above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5f64fa7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß System Status Check\n",
        "\n",
        "def check_system_status():\n",
        "    \"\"\"Check if all components are properly initialized\"\"\"\n",
        "    \n",
        "    print(\"üîç System Status Check\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Check components\n",
        "    status = {\n",
        "        'Python Version': sys.version_info >= (3, 8),\n",
        "        'API Key': OPENAI_API_KEY is not None,\n",
        "        'Research Assistant': 'research_assistant' in globals() and research_assistant is not None,\n",
        "        'Document Processor': 'doc_processor' in globals() and doc_processor is not None,\n",
        "        'Memory System': 'research_memory' in globals() and research_memory is not None,\n",
        "        'Required Libraries': True  # Will be checked below\n",
        "    }\n",
        "    \n",
        "    # Check required libraries\n",
        "    try:\n",
        "        import langchain\n",
        "        import openai\n",
        "        import tiktoken\n",
        "        import pandas as pd\n",
        "        import matplotlib.pyplot as plt\n",
        "        import plotly.express as px\n",
        "        status['Required Libraries'] = True\n",
        "    except ImportError as e:\n",
        "        status['Required Libraries'] = False\n",
        "        print(f\"‚ö†Ô∏è  Missing library: {e}\")\n",
        "    \n",
        "    # Display status\n",
        "    all_ready = True\n",
        "    for component, is_ready in status.items():\n",
        "        emoji = \"‚úÖ\" if is_ready else \"‚ùå\"\n",
        "        status_text = \"Ready\" if is_ready else \"Not Ready\"\n",
        "        print(f\"{emoji} {component}: {status_text}\")\n",
        "        if not is_ready:\n",
        "            all_ready = False\n",
        "    \n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    if all_ready:\n",
        "        print(\"üéâ All systems ready! You can start researching.\")\n",
        "        print(\"üí° Try running the example cells below to get started.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Some components need attention.\")\n",
        "        print(\"üìù Please check the setup cells above and ensure:\")\n",
        "        print(\"   ‚Ä¢ All dependencies are installed\")\n",
        "        print(\"   ‚Ä¢ OpenAI API key is configured\")\n",
        "        print(\"   ‚Ä¢ All previous cells have been executed\")\n",
        "    \n",
        "    return all_ready\n",
        "\n",
        "def display_system_info():\n",
        "    \"\"\"Display detailed system information\"\"\"\n",
        "    \n",
        "    if not check_system_status():\n",
        "        return\n",
        "    \n",
        "    print(\"\\nüìä System Information\")\n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    # Display current preferences\n",
        "    if 'research_memory' in globals() and research_memory:\n",
        "        print(\"üéØ Current Research Preferences:\")\n",
        "        for key, value in research_memory.preferences.items():\n",
        "            print(f\"   {key}: {value}\")\n",
        "        \n",
        "        print(f\"\\nüìà Session Statistics:\")\n",
        "        stats = research_memory.get_session_summary()\n",
        "        for key, value in stats.items():\n",
        "            print(f\"   {key}: {value}\")\n",
        "    \n",
        "    # Display cost estimation\n",
        "    print(f\"\\nüí∞ Cost Estimation (per query):\")\n",
        "    print(f\"   Small query (~500 tokens): $0.001 - $0.003\")\n",
        "    print(f\"   Medium query (~1500 tokens): $0.003 - $0.007\")\n",
        "    print(f\"   Large query (~3000 tokens): $0.007 - $0.015\")\n",
        "    \n",
        "    print(f\"\\nüöÄ Ready to Research!\")\n",
        "    print(f\"üí° Example usage:\")\n",
        "    print(f\"   result = research_assistant.research('your question here')\")\n",
        "\n",
        "# Run the system check\n",
        "print(\"üîç Checking system status...\")\n",
        "system_ready = check_system_status()\n",
        "\n",
        "# Display additional info if ready\n",
        "if system_ready:\n",
        "    display_system_info()\n",
        "else:\n",
        "    print(\"\\nüîß Setup Guide:\")\n",
        "    print(\"1. Run the installation cell to install dependencies\")\n",
        "    print(\"2. Configure your OpenAI API key\")\n",
        "    print(\"3. Execute all setup cells in order\")\n",
        "    print(\"4. Run this cell again to verify status\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a49e0ff",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîç Example 1: Basic Research Query\n",
        "\n",
        "def run_basic_research_demo():\n",
        "    \"\"\"Demonstrate basic research functionality\"\"\"\n",
        "    \n",
        "    if not system_ready:\n",
        "        print(\"‚ö†Ô∏è  System not ready. Please complete the setup first.\")\n",
        "        print(\"üí° Make sure to set your OpenAI API key in the configuration cell above.\")\n",
        "        return\n",
        "    \n",
        "    print(\"üöÄ Basic Research Demo\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Example research query\n",
        "    example_query = \"What are the latest developments in renewable energy technology?\"\n",
        "    \n",
        "    print(f\"üìù Research Query: {example_query}\")\n",
        "    print(\"‚è≥ Processing... (This may take 30-60 seconds)\")\n",
        "    print(\"üîç Searching multiple sources...\")\n",
        "    \n",
        "    try:\n",
        "        # Perform research\n",
        "        result = research_assistant.research(example_query, include_analysis=True)\n",
        "        \n",
        "        # Display results\n",
        "        if not result.get('error'):\n",
        "            print(\"\\n‚úÖ Research Completed Successfully!\")\n",
        "            print(\"=\" * 50)\n",
        "            \n",
        "            # Main findings\n",
        "            print(\"üìä **Research Findings:**\")\n",
        "            print(\"-\" * 30)\n",
        "            print(result['findings'])\n",
        "            \n",
        "            # Metadata\n",
        "            print(f\"\\nüìà **Research Metadata:**\")\n",
        "            print(f\"   üìö Sources Found: {len(result['sources'])}\")\n",
        "            print(f\"   üí∞ Cost: ${result['cost']:.4f}\")\n",
        "            print(f\"   üî¢ Tokens Used: {result['tokens_used']:,}\")\n",
        "            print(f\"   ‚è±Ô∏è Processing Time: {result['processing_time']:.2f} seconds\")\n",
        "            \n",
        "            # Sources\n",
        "            print(f\"\\nüìö **Sources:**\")\n",
        "            for i, source in enumerate(result['sources'], 1):\n",
        "                print(f\"   {i}. {source[:100]}{'...' if len(source) > 100 else ''}\")\n",
        "            \n",
        "            # Quality analysis\n",
        "            if 'analysis' in result:\n",
        "                analysis = result['analysis']\n",
        "                print(f\"\\nüß† **Quality Analysis:**\")\n",
        "                print(f\"   üìù Word Count: {analysis['word_count']}\")\n",
        "                print(f\"   üéØ Completeness Score: {analysis['completeness_score']:.2f}/1.0\")\n",
        "                print(f\"   üìñ Has Citations: {analysis['has_citations']}\")\n",
        "                print(f\"   üîç Confidence Indicators: {len(analysis['confidence_indicators'])}\")\n",
        "                \n",
        "                # Quality rating\n",
        "                score = analysis['completeness_score']\n",
        "                if score >= 0.8:\n",
        "                    rating = \"üåü Excellent\"\n",
        "                elif score >= 0.6:\n",
        "                    rating = \"üëç Good\"\n",
        "                elif score >= 0.4:\n",
        "                    rating = \"‚ö†Ô∏è Fair\"\n",
        "                else:\n",
        "                    rating = \"‚ùå Poor\"\n",
        "                print(f\"   üèÜ Quality Rating: {rating}\")\n",
        "            \n",
        "            print(\"\\nüéâ Demo completed successfully!\")\n",
        "            \n",
        "        else:\n",
        "            print(\"‚ùå Research failed:\")\n",
        "            print(result['findings'])\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during research: {str(e)}\")\n",
        "        print(\"üí° Check your API key and internet connection\")\n",
        "\n",
        "# Run the demo\n",
        "print(\"üéØ Basic Research Example\")\n",
        "print(\"This example demonstrates the core research functionality\")\n",
        "print(\"with a sample query about renewable energy technology.\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Only run if system is ready\n",
        "if 'system_ready' in globals():\n",
        "    run_basic_research_demo()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Please run the system status check cell first.\")\n",
        "    print(\"üí° Make sure all previous cells have been executed successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "035ed1b5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üí¨ Interactive Research Interface\n",
        "\n",
        "def interactive_research():\n",
        "    \"\"\"Interactive research session\"\"\"\n",
        "    if not system_ready:\n",
        "        print(\"‚ö†Ô∏è  System not ready. Please complete the setup first.\")\n",
        "        return\n",
        "    \n",
        "    print(\"üéØ Interactive Research Session Started!\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"üí° Tips:\")\n",
        "    print(\"   - Ask specific questions for better results\")\n",
        "    print(\"   - Use keywords like 'latest', 'trends', 'comparison'\")\n",
        "    print(\"   - Type 'quit' to exit\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    while True:\n",
        "        try:\n",
        "            # Get user input\n",
        "            user_query = input(\"\\nüîç Enter your research question: \").strip()\n",
        "            \n",
        "            if user_query.lower() in ['quit', 'exit', 'q']:\n",
        "                print(\"üëã Research session ended. Thank you!\")\n",
        "                break\n",
        "            \n",
        "            if not user_query:\n",
        "                print(\"‚ö†Ô∏è  Please enter a valid question.\")\n",
        "                continue\n",
        "            \n",
        "            print(f\"\\n‚è≥ Researching: {user_query}\")\n",
        "            print(\"Please wait...\")\n",
        "            \n",
        "            # Perform research\n",
        "            result = research_assistant.research(user_query, include_analysis=True)\n",
        "            \n",
        "            # Display results\n",
        "            if not result.get('error'):\n",
        "                print(\"\\n\" + \"=\"*80)\n",
        "                print(\"üìä RESEARCH FINDINGS:\")\n",
        "                print(\"=\"*80)\n",
        "                print(result['findings'])\n",
        "                \n",
        "                print(f\"\\nüìà SUMMARY:\")\n",
        "                print(f\"   üí∞ Cost: ${result['cost']:.4f}\")\n",
        "                print(f\"   üìö Sources: {len(result['sources'])}\")\n",
        "                print(f\"   ‚è±Ô∏è  Time: {result['processing_time']:.2f}s\")\n",
        "                \n",
        "                if 'analysis' in result:\n",
        "                    score = result['analysis']['completeness_score']\n",
        "                    print(f\"   üéØ Quality Score: {score:.2f}/1.0\")\n",
        "                \n",
        "                print(\"=\"*80)\n",
        "            else:\n",
        "                print(f\"‚ùå Research failed: {result['findings']}\")\n",
        "                \n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nüëã Research session interrupted.\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error: {str(e)}\")\n",
        "\n",
        "# Note: Uncomment the line below to start an interactive session\n",
        "# interactive_research()\n",
        "\n",
        "print(\"üí° Interactive Research Interface Ready!\")\n",
        "print(\"üìù Uncomment the last line in this cell to start an interactive session.\")\n",
        "print(\"üéØ Or use the research_assistant.research() method directly with your queries.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "319420a4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìÑ Document Processing Examples\n",
        "\n",
        "def document_processing_demo():\n",
        "    \"\"\"Demonstrate document processing capabilities\"\"\"\n",
        "    if not system_ready:\n",
        "        print(\"‚ö†Ô∏è  System not ready. Please complete the setup first.\")\n",
        "        return\n",
        "    \n",
        "    print(\"üìÑ Document Processing Demo\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Example 1: Process text documents\n",
        "    print(\"üìù Example 1: Processing Sample Documents\")\n",
        "    \n",
        "    sample_docs = [\n",
        "        \"\"\"\n",
        "        Artificial Intelligence (AI) has revolutionized various industries in recent years. \n",
        "        Machine learning algorithms are being used in healthcare to diagnose diseases, \n",
        "        in finance for fraud detection, and in transportation for autonomous vehicles. \n",
        "        The key benefits include improved accuracy, reduced costs, and enhanced efficiency.\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        Climate change is one of the most pressing challenges of our time. \n",
        "        Rising global temperatures are causing sea levels to rise, weather patterns to change, \n",
        "        and ecosystems to be disrupted. Renewable energy sources like solar and wind power \n",
        "        are crucial for reducing carbon emissions and combating climate change.\n",
        "        \"\"\",\n",
        "        \"\"\"\n",
        "        Quantum computing represents a paradigm shift in computational power. \n",
        "        Unlike classical computers that use bits, quantum computers use quantum bits (qubits) \n",
        "        which can exist in multiple states simultaneously. This enables them to solve \n",
        "        certain problems exponentially faster than classical computers.\n",
        "        \"\"\"\n",
        "    ]\n",
        "    \n",
        "    metadata = [\n",
        "        {\"source\": \"AI Research Paper\", \"topic\": \"artificial_intelligence\"},\n",
        "        {\"source\": \"Climate Report\", \"topic\": \"climate_change\"},\n",
        "        {\"source\": \"Quantum Computing Review\", \"topic\": \"quantum_computing\"}\n",
        "    ]\n",
        "    \n",
        "    # Process documents\n",
        "    print(\"‚è≥ Processing sample documents...\")\n",
        "    doc_processor.process_documents(sample_docs, metadata)\n",
        "    \n",
        "    # Get document stats\n",
        "    stats = doc_processor.get_document_stats()\n",
        "    print(f\"‚úÖ Processed {stats['total_documents']} documents into {stats['total_chunks']} chunks\")\n",
        "    \n",
        "    # Example 2: Query documents\n",
        "    print(\"\\nüîç Example 2: Querying Documents\")\n",
        "    \n",
        "    sample_queries = [\n",
        "        \"What are the benefits of AI?\",\n",
        "        \"How does climate change affect the environment?\",\n",
        "        \"What makes quantum computing different from classical computing?\"\n",
        "    ]\n",
        "    \n",
        "    for i, query in enumerate(sample_queries, 1):\n",
        "        print(f\"\\nüìù Query {i}: {query}\")\n",
        "        result = doc_processor.query_documents(query, k=2)\n",
        "        print(\"üìä Results:\")\n",
        "        print(result[:300] + \"...\" if len(result) > 300 else result)\n",
        "    \n",
        "    print(\"\\n‚úÖ Document processing demo completed!\")\n",
        "\n",
        "# Example 3: Add document from URL (commented out - requires internet)\n",
        "def add_web_document_example():\n",
        "    \"\"\"Example of adding a document from a URL\"\"\"\n",
        "    if not system_ready:\n",
        "        return\n",
        "    \n",
        "    print(\"üåê Adding Document from URL Example\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Example URLs (uncomment to try)\n",
        "    example_urls = [\n",
        "        \"https://en.wikipedia.org/wiki/Artificial_intelligence\",\n",
        "        \"https://en.wikipedia.org/wiki/Climate_change\",\n",
        "        \"https://en.wikipedia.org/wiki/Quantum_computing\"\n",
        "    ]\n",
        "    \n",
        "    print(\"üìù Example URLs that can be processed:\")\n",
        "    for i, url in enumerate(example_urls, 1):\n",
        "        print(f\"   {i}. {url}\")\n",
        "    \n",
        "    print(\"\\nüí° To add a document from URL, use:\")\n",
        "    print(\"   doc_processor.add_document_from_url('your_url_here')\")\n",
        "    print(\"   result = doc_processor.query_documents('your_query_here')\")\n",
        "\n",
        "# Run the document processing demo\n",
        "if system_ready:\n",
        "    document_processing_demo()\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    add_web_document_example()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Please complete the system setup first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d840802",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä Research Analytics and Visualization\n",
        "\n",
        "def visualize_research_trends():\n",
        "    \"\"\"Create visualizations of research trends and statistics\"\"\"\n",
        "    if not research_memory.research_history:\n",
        "        print(\"‚ö†Ô∏è  No research history available. Please run some research queries first.\")\n",
        "        return\n",
        "    \n",
        "    print(\"üìà Research Analytics Dashboard\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Prepare data\n",
        "    history = research_memory.research_history\n",
        "    \n",
        "    # Create a DataFrame for analysis\n",
        "    data = []\n",
        "    for entry in history:\n",
        "        data.append({\n",
        "            'timestamp': entry['timestamp'],\n",
        "            'query_length': len(entry['query']),\n",
        "            'cost': entry['cost'],\n",
        "            'tokens': entry['tokens'],\n",
        "            'hour': entry['timestamp'].hour\n",
        "        })\n",
        "    \n",
        "    if not data:\n",
        "        print(\"‚ö†Ô∏è  No data to visualize yet.\")\n",
        "        return\n",
        "    \n",
        "    df = pd.DataFrame(data)\n",
        "    \n",
        "    # Create visualizations\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('Research Assistant Analytics Dashboard', fontsize=16)\n",
        "    \n",
        "    # 1. Research costs over time\n",
        "    axes[0, 0].plot(df.index, df['cost'], marker='o', linewidth=2)\n",
        "    axes[0, 0].set_title('Research Costs per Query')\n",
        "    axes[0, 0].set_xlabel('Query Number')\n",
        "    axes[0, 0].set_ylabel('Cost ($)')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Token usage distribution\n",
        "    axes[0, 1].hist(df['tokens'], bins=10, alpha=0.7, color='skyblue')\n",
        "    axes[0, 1].set_title('Token Usage Distribution')\n",
        "    axes[0, 1].set_xlabel('Tokens Used')\n",
        "    axes[0, 1].set_ylabel('Frequency')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. Query length vs cost\n",
        "    axes[1, 0].scatter(df['query_length'], df['cost'], alpha=0.7, color='green')\n",
        "    axes[1, 0].set_title('Query Length vs Cost')\n",
        "    axes[1, 0].set_xlabel('Query Length (characters)')\n",
        "    axes[1, 0].set_ylabel('Cost ($)')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Research activity by hour\n",
        "    if len(df) > 1:\n",
        "        hourly_counts = df['hour'].value_counts().sort_index()\n",
        "        axes[1, 1].bar(hourly_counts.index, hourly_counts.values, alpha=0.7, color='orange')\n",
        "        axes[1, 1].set_title('Research Activity by Hour')\n",
        "        axes[1, 1].set_xlabel('Hour of Day')\n",
        "        axes[1, 1].set_ylabel('Number of Queries')\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "    else:\n",
        "        axes[1, 1].text(0.5, 0.5, 'Need more data\\nfor hourly analysis', \n",
        "                       ha='center', va='center', fontsize=12)\n",
        "        axes[1, 1].set_title('Research Activity by Hour')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print summary statistics\n",
        "    print(\"\\nüìä Research Session Summary:\")\n",
        "    print(\"=\" * 30)\n",
        "    stats = research_memory.get_session_summary()\n",
        "    print(f\"Total Queries: {stats['queries_conducted']}\")\n",
        "    print(f\"Total Cost: ${stats['total_cost']:.4f}\")\n",
        "    print(f\"Total Tokens: {stats['total_tokens']:,}\")\n",
        "    print(f\"Average Cost per Query: ${stats['avg_cost_per_query']:.4f}\")\n",
        "    print(f\"Session Duration: {stats['session_duration']}\")\n",
        "    \n",
        "    return df\n",
        "\n",
        "def create_research_report():\n",
        "    \"\"\"Generate a comprehensive research report\"\"\"\n",
        "    if not research_memory.research_history:\n",
        "        print(\"‚ö†Ô∏è  No research history available.\")\n",
        "        return\n",
        "    \n",
        "    print(\"üìÑ Generating Research Report...\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Create report data\n",
        "    report_data = []\n",
        "    for i, entry in enumerate(research_memory.research_history, 1):\n",
        "        report_data.append({\n",
        "            'Query #': i,\n",
        "            'Timestamp': entry['timestamp'].strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'Query': entry['query'][:100] + \"...\" if len(entry['query']) > 100 else entry['query'],\n",
        "            'Cost ($)': f\"{entry['cost']:.4f}\",\n",
        "            'Tokens': entry['tokens'],\n",
        "            'Success': 'Yes' if not entry['result'].get('error') else 'No'\n",
        "        })\n",
        "    \n",
        "    # Create DataFrame and display\n",
        "    report_df = pd.DataFrame(report_data)\n",
        "    \n",
        "    print(\"üìä Research History Report:\")\n",
        "    print(report_df.to_string(index=False))\n",
        "    \n",
        "    # Export options\n",
        "    print(f\"\\nüíæ Export Options:\")\n",
        "    print(\"   ‚Ä¢ CSV: report_df.to_csv('research_report.csv', index=False)\")\n",
        "    print(\"   ‚Ä¢ Excel: report_df.to_excel('research_report.xlsx', index=False)\")\n",
        "    print(\"   ‚Ä¢ JSON: report_df.to_json('research_report.json', orient='records')\")\n",
        "    \n",
        "    return report_df\n",
        "\n",
        "# Run analytics if we have data\n",
        "if research_memory.research_history:\n",
        "    analytics_df = visualize_research_trends()\n",
        "    report_df = create_research_report()\n",
        "else:\n",
        "    print(\"üìä Analytics Dashboard Ready!\")\n",
        "    print(\"üí° Run some research queries first to see analytics and visualizations.\")\n",
        "    print(\"üéØ Use: research_assistant.research('your question here')\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e33032d4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß Utility Functions and Advanced Features\n",
        "\n",
        "def update_research_preferences():\n",
        "    \"\"\"Update research preferences interactively\"\"\"\n",
        "    if not system_ready:\n",
        "        print(\"‚ö†Ô∏è  System not ready.\")\n",
        "        return\n",
        "    \n",
        "    print(\"‚öôÔ∏è  Research Preferences Configuration\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    current_prefs = research_memory.preferences\n",
        "    print(\"üìä Current Preferences:\")\n",
        "    for key, value in current_prefs.items():\n",
        "        print(f\"   {key}: {value}\")\n",
        "    \n",
        "    print(\"\\nüéØ Available Options:\")\n",
        "    print(\"   1. summary_style: 'brief', 'comprehensive', 'technical'\")\n",
        "    print(\"   2. max_results: 1-10\")\n",
        "    print(\"   3. include_analysis: True/False\")\n",
        "    \n",
        "    try:\n",
        "        choice = input(\"\\nEnter preference to update (or 'skip' to continue): \").strip()\n",
        "        \n",
        "        if choice.lower() == 'skip':\n",
        "            print(\"‚úÖ Preferences unchanged.\")\n",
        "            return\n",
        "        \n",
        "        if choice in current_prefs:\n",
        "            new_value = input(f\"Enter new value for {choice}: \").strip()\n",
        "            \n",
        "            # Convert to appropriate type\n",
        "            if choice == 'max_results':\n",
        "                new_value = int(new_value)\n",
        "            elif choice == 'include_analysis':\n",
        "                new_value = new_value.lower() == 'true'\n",
        "            \n",
        "            research_memory.update_preferences(choice, new_value)\n",
        "        else:\n",
        "            print(\"‚ùå Invalid preference name.\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error updating preferences: {e}\")\n",
        "\n",
        "def export_research_data():\n",
        "    \"\"\"Export research data in various formats\"\"\"\n",
        "    if not research_memory.research_history:\n",
        "        print(\"‚ö†Ô∏è  No research data to export.\")\n",
        "        return\n",
        "    \n",
        "    print(\"üíæ Data Export Options\")\n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    # Prepare export data\n",
        "    export_data = []\n",
        "    for entry in research_memory.research_history:\n",
        "        export_data.append({\n",
        "            'timestamp': entry['timestamp'].isoformat(),\n",
        "            'query': entry['query'],\n",
        "            'findings': entry['result'].get('findings', ''),\n",
        "            'sources': entry['result'].get('sources', []),\n",
        "            'cost': entry['cost'],\n",
        "            'tokens': entry['tokens']\n",
        "        })\n",
        "    \n",
        "    # JSON export\n",
        "    print(\"üìÑ Exporting to JSON...\")\n",
        "    with open('research_data.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
        "    print(\"‚úÖ Exported to: research_data.json\")\n",
        "    \n",
        "    # CSV export\n",
        "    print(\"üìä Exporting to CSV...\")\n",
        "    df = pd.DataFrame(export_data)\n",
        "    df['sources'] = df['sources'].astype(str)  # Convert list to string for CSV\n",
        "    df.to_csv('research_data.csv', index=False)\n",
        "    print(\"‚úÖ Exported to: research_data.csv\")\n",
        "    \n",
        "    # Excel export\n",
        "    print(\"üìà Exporting to Excel...\")\n",
        "    with pd.ExcelWriter('research_data.xlsx', engine='openpyxl') as writer:\n",
        "        df.to_excel(writer, sheet_name='Research Data', index=False)\n",
        "        \n",
        "        # Add a summary sheet\n",
        "        summary_df = pd.DataFrame([research_memory.get_session_summary()])\n",
        "        summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
        "    \n",
        "    print(\"‚úÖ Exported to: research_data.xlsx\")\n",
        "    print(\"\\nüìÅ Files created in the current directory:\")\n",
        "    print(\"   ‚Ä¢ research_data.json\")\n",
        "    print(\"   ‚Ä¢ research_data.csv\")\n",
        "    print(\"   ‚Ä¢ research_data.xlsx\")\n",
        "\n",
        "def batch_research(queries: List[str], delay: float = 2.0):\n",
        "    \"\"\"Perform batch research on multiple queries\"\"\"\n",
        "    if not system_ready:\n",
        "        print(\"‚ö†Ô∏è  System not ready.\")\n",
        "        return\n",
        "    \n",
        "    print(f\"üîÑ Batch Research: {len(queries)} queries\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    results = []\n",
        "    total_cost = 0.0\n",
        "    \n",
        "    for i, query in enumerate(queries, 1):\n",
        "        print(f\"\\nüìù Processing Query {i}/{len(queries)}: {query}\")\n",
        "        \n",
        "        result = research_assistant.research(query, include_analysis=True)\n",
        "        results.append(result)\n",
        "        \n",
        "        if not result.get('error'):\n",
        "            total_cost += result['cost']\n",
        "            print(f\"‚úÖ Completed - Cost: ${result['cost']:.4f}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Failed: {result['findings']}\")\n",
        "        \n",
        "        # Add delay between requests\n",
        "        if i < len(queries):\n",
        "            print(f\"‚è≥ Waiting {delay} seconds...\")\n",
        "            import time\n",
        "            time.sleep(delay)\n",
        "    \n",
        "    print(f\"\\nüéâ Batch Research Complete!\")\n",
        "    print(f\"üí∞ Total Cost: ${total_cost:.4f}\")\n",
        "    print(f\"‚úÖ Successful: {len([r for r in results if not r.get('error')])}\")\n",
        "    print(f\"‚ùå Failed: {len([r for r in results if r.get('error')])}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "def clear_research_history():\n",
        "    \"\"\"Clear research history and reset statistics\"\"\"\n",
        "    if not research_memory:\n",
        "        print(\"‚ö†Ô∏è  Memory system not available.\")\n",
        "        return\n",
        "    \n",
        "    confirm = input(\"‚ö†Ô∏è  Are you sure you want to clear all research history? (yes/no): \").strip().lower()\n",
        "    \n",
        "    if confirm == 'yes':\n",
        "        research_memory.research_history.clear()\n",
        "        research_memory.session_stats = {\n",
        "            'queries_conducted': 0,\n",
        "            'total_tokens': 0,\n",
        "            'total_cost': 0.0,\n",
        "            'session_start': datetime.now()\n",
        "        }\n",
        "        print(\"‚úÖ Research history cleared.\")\n",
        "    else:\n",
        "        print(\"‚ùå Operation cancelled.\")\n",
        "\n",
        "# Example usage\n",
        "print(\"üîß Utility Functions Available:\")\n",
        "print(\"   ‚Ä¢ update_research_preferences() - Configure research settings\")\n",
        "print(\"   ‚Ä¢ export_research_data() - Export research data to files\")\n",
        "print(\"   ‚Ä¢ batch_research(queries) - Research multiple topics at once\")\n",
        "print(\"   ‚Ä¢ clear_research_history() - Clear all research history\")\n",
        "print(\"   ‚Ä¢ research_memory.get_session_summary() - Get current session stats\")\n",
        "\n",
        "# Quick preference update\n",
        "print(f\"\\n‚öôÔ∏è  Quick Preference Update:\")\n",
        "print(\"   research_memory.update_preferences('summary_style', 'brief')\")\n",
        "print(\"   research_memory.update_preferences('max_results', 7)\")\n",
        "print(\"   research_memory.update_preferences('include_analysis', True)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efc86df2",
      "metadata": {},
      "source": [
        "## üéâ Conclusion and Next Steps\n",
        "\n",
        "### üéØ **What You've Built**\n",
        "\n",
        "Congratulations! You now have a fully functional AI Research Assistant with comprehensive capabilities:\n",
        "\n",
        "#### ‚úÖ **Core Features**\n",
        "- üåê **Multi-source Research**: Web search, arXiv, and Google Scholar integration\n",
        "- üß† **Intelligent Memory**: Contextual memory for research history and preferences\n",
        "- üìÑ **Document Processing**: Vector storage and semantic search capabilities\n",
        "- üí∞ **Cost Tracking**: Monitor API usage and costs in real-time\n",
        "- üéØ **Quality Analysis**: Automated assessment of research quality and completeness\n",
        "\n",
        "#### üîß **Advanced Features**\n",
        "- üí¨ **Interactive Interface**: Command-line style research sessions\n",
        "- üîÑ **Batch Processing**: Research multiple topics simultaneously\n",
        "- üìä **Data Export**: Export research data in JSON, CSV, and Excel formats\n",
        "- üìà **Analytics Dashboard**: Visualize research trends and statistics\n",
        "- ‚öôÔ∏è **Preference Management**: Customize research behavior and settings\n",
        "\n",
        "### üöÄ **Getting Started Quickly**\n",
        "\n",
        "```python\n",
        "# 1. Basic research\n",
        "result = research_assistant.research(\"What is quantum computing?\")\n",
        "print(result['findings'])\n",
        "\n",
        "# 2. Batch research\n",
        "queries = [\"AI in healthcare\", \"Climate change solutions\", \"Renewable energy\"]\n",
        "results = batch_research(queries)\n",
        "\n",
        "# 3. Document processing\n",
        "doc_processor.add_document_from_url(\"https://example.com/article\")\n",
        "doc_result = doc_processor.query_documents(\"key concepts\")\n",
        "\n",
        "# 4. Export your research\n",
        "export_research_data()\n",
        "```\n",
        "\n",
        "### üåü **Community and Contributions**\n",
        "\n",
        "We welcome contributions from the community! Here's how you can help:\n",
        "\n",
        "#### ü§ù **How to Contribute**\n",
        "1. üç¥ **Fork** the repository\n",
        "2. üåø **Create** a feature branch (`git checkout -b feature/amazing-feature`)\n",
        "3. üíæ **Commit** your changes (`git commit -m 'Add amazing feature'`)\n",
        "4. üì§ **Push** to the branch (`git push origin feature/amazing-feature`)\n",
        "5. üîÉ **Open** a Pull Request\n",
        "\n",
        "#### üéØ **Areas for Contribution**\n",
        "- üîç **New Search Sources**: Add more academic databases\n",
        "- üìä **Enhanced Analytics**: Improve visualization and reporting\n",
        "- üåê **Web Interface**: Enhance the Streamlit application\n",
        "- üß† **AI Models**: Integration with other LLM providers\n",
        "- üìö **Documentation**: Improve guides and tutorials\n",
        "- üêõ **Bug Fixes**: Help us identify and fix issues\n",
        "\n",
        "### üöÄ **Next Steps and Enhancements**\n",
        "\n",
        "1. **üîó Additional Integrations**\n",
        "   - Google Scholar API for better academic search\n",
        "   - Semantic Scholar for computer science papers\n",
        "   - PubMed for medical research\n",
        "   - Patent databases for innovation research\n",
        "\n",
        "2. **üìä Enhanced Analytics**\n",
        "   - Sentiment analysis of research findings\n",
        "   - Topic modeling and clustering\n",
        "   - Research trend predictions\n",
        "   - Collaboration network analysis\n",
        "\n",
        "3. **üåê Web Interface**\n",
        "   - Deploy the Streamlit app: `streamlit run research_app.py`\n",
        "   - Add user authentication and project sharing\n",
        "   - Real-time collaboration features\n",
        "\n",
        "4. **ü§ñ AI Improvements**\n",
        "   - Fine-tuning for specific research domains\n",
        "   - Multi-language support\n",
        "   - Voice-to-text research queries\n",
        "   - Automated report generation\n",
        "\n",
        "### üìö **Additional Resources**\n",
        "\n",
        "- üìñ **Documentation**: [README.md](README.md)\n",
        "- üåê **Web App**: Run `streamlit run research_app.py`\n",
        "- üêô **GitHub Setup**: [GITHUB_SETUP.md](GITHUB_SETUP.md)\n",
        "- üìÑ **License**: [MIT License](LICENSE)\n",
        "- üîó **OpenAI API**: [Get your API key](https://platform.openai.com/api-keys)\n",
        "\n",
        "### üõ†Ô∏è **Troubleshooting**\n",
        "\n",
        "| Issue | Solution |\n",
        "|-------|----------|\n",
        "| üîë **API Key Issues** | Ensure OpenAI API key is correctly set in environment variables |\n",
        "| üåê **Network Problems** | Check internet connection for web searches |\n",
        "| üíæ **Memory Issues** | Clear research history: `clear_research_history()` |\n",
        "| üí∞ **Cost Concerns** | Monitor usage with analytics dashboard |\n",
        "| üì¶ **Import Errors** | Reinstall dependencies: `pip install -r requirements.txt` |\n",
        "\n",
        "### üîí **Security Best Practices**\n",
        "\n",
        "- üîê **Never commit** `.env` files or API keys to version control\n",
        "- üåç **Use environment variables** for all sensitive configuration\n",
        "- üìä **Monitor API usage** regularly to prevent unexpected costs\n",
        "- üîÑ **Keep dependencies updated** for security patches\n",
        "- üõ°Ô∏è **Use strong authentication** for deployed applications\n",
        "\n",
        "### üìû **Support and Community**\n",
        "\n",
        "- üêõ **Bug Reports**: [Create an issue](https://github.com/yourusername/ai-research-assistant/issues)\n",
        "- üí° **Feature Requests**: [Start a discussion](https://github.com/yourusername/ai-research-assistant/discussions)\n",
        "- ‚ùì **Questions**: [Check the FAQ](https://github.com/yourusername/ai-research-assistant/wiki/FAQ)\n",
        "- üí¨ **Chat**: [Join our Discord](https://discord.gg/your-server)\n",
        "\n",
        "### üèÜ **Acknowledgments**\n",
        "\n",
        "- ü¶ú **LangChain**: For the amazing framework\n",
        "- ü§ñ **OpenAI**: For the powerful language models\n",
        "- üåü **Open Source Community**: For all the amazing libraries\n",
        "- üë• **Contributors**: Everyone who helps improve this project\n",
        "\n",
        "---\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "**üî¨ Happy Researching! üìäüöÄ**\n",
        "\n",
        "[![GitHub stars](https://img.shields.io/github/stars/yourusername/ai-research-assistant?style=social)](https://github.com/yourusername/ai-research-assistant)\n",
        "[![Twitter Follow](https://img.shields.io/twitter/follow/yourusername?style=social)](https://twitter.com/yourusername)\n",
        "\n",
        "*Made with ‚ù§Ô∏è by the AI Research Assistant community*\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f613e95e",
      "metadata": {},
      "source": [
        "## üêô GitHub Repository Information\n",
        "\n",
        "### üìã **Repository Structure**\n",
        "\n",
        "```\n",
        "ai-research-assistant/\n",
        "‚îú‚îÄ‚îÄ üìì custom_research_assistant.ipynb  # Main notebook (this file)\n",
        "‚îú‚îÄ‚îÄ üåê research_app.py                  # Streamlit web interface\n",
        "‚îú‚îÄ‚îÄ üì¶ requirements.txt                 # Python dependencies\n",
        "‚îú‚îÄ‚îÄ üìñ README.md                        # Project documentation\n",
        "‚îú‚îÄ‚îÄ üîß .env.example                     # Environment variables template\n",
        "‚îú‚îÄ‚îÄ üö´ .gitignore                       # Git ignore file\n",
        "‚îú‚îÄ‚îÄ üìÑ LICENSE                          # MIT license\n",
        "‚îú‚îÄ‚îÄ üêô GITHUB_SETUP.md                  # GitHub setup instructions\n",
        "‚îî‚îÄ‚îÄ üì§ upload_to_github.ps1             # Upload script for Windows\n",
        "```\n",
        "\n",
        "### üîÑ **Version Information**\n",
        "\n",
        "- **Version**: 1.0.0\n",
        "- **Last Updated**: July 2025\n",
        "- **Python**: 3.8+\n",
        "- **LangChain**: 0.1.0+\n",
        "- **OpenAI**: GPT-3.5-turbo\n",
        "\n",
        "### üè∑Ô∏è **Repository Tags**\n",
        "\n",
        "`ai` `research` `langchain` `openai` `jupyter` `data-science` `machine-learning` `nlp` `automation` `productivity`\n",
        "\n",
        "### üìà **Project Stats**\n",
        "\n",
        "| Metric | Value |\n",
        "|--------|-------|\n",
        "| üìä **Lines of Code** | 2000+ |\n",
        "| üîß **Functions** | 50+ |\n",
        "| üìù **Documentation** | Comprehensive |\n",
        "| üß™ **Examples** | 10+ |\n",
        "| üåü **Features** | 15+ |\n",
        "\n",
        "### üöÄ **Quick Deploy**\n",
        "\n",
        "#### Deploy to GitHub Pages\n",
        "```bash\n",
        "git clone https://github.com/yourusername/ai-research-assistant.git\n",
        "cd ai-research-assistant\n",
        "pip install -r requirements.txt\n",
        "streamlit run research_app.py\n",
        "```\n",
        "\n",
        "#### Deploy to Heroku\n",
        "```bash\n",
        "git clone https://github.com/yourusername/ai-research-assistant.git\n",
        "cd ai-research-assistant\n",
        "heroku create your-app-name\n",
        "git push heroku main\n",
        "```\n",
        "\n",
        "#### Deploy to Google Colab\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yourusername/ai-research-assistant/blob/main/custom_research_assistant.ipynb)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a82be3a4",
      "metadata": {},
      "source": [
        "## üìú License and Citation\n",
        "\n",
        "### üìÑ **License**\n",
        "\n",
        "This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n",
        "\n",
        "```\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2025 AI Research Assistant Contributors\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "```\n",
        "\n",
        "### üìö **Citation**\n",
        "\n",
        "If you use this work in your research or projects, please cite it as:\n",
        "\n",
        "```bibtex\n",
        "@software{ai_research_assistant,\n",
        "  title = {AI Research Assistant: A Comprehensive Research Tool Built with LangChain},\n",
        "  author = {AI Research Assistant Contributors},\n",
        "  year = {2025},\n",
        "  url = {https://github.com/yourusername/ai-research-assistant},\n",
        "  version = {1.0.0}\n",
        "}\n",
        "```\n",
        "\n",
        "### üôè **Acknowledgments**\n",
        "\n",
        "This project builds upon the excellent work of:\n",
        "\n",
        "- **LangChain**: Harrison Chase and the LangChain team for the amazing framework\n",
        "- **OpenAI**: For providing powerful language models and APIs\n",
        "- **Streamlit**: For the beautiful web application framework\n",
        "- **Plotly**: For interactive visualizations\n",
        "- **ChromaDB**: For vector storage capabilities\n",
        "- **ArXiv**: For academic paper access\n",
        "- **DuckDuckGo**: For web search capabilities\n",
        "\n",
        "### üîó **Related Projects**\n",
        "\n",
        "- [LangChain](https://github.com/langchain-ai/langchain) - Framework for developing applications with LLMs\n",
        "- [Streamlit](https://github.com/streamlit/streamlit) - Web app framework for ML and data science\n",
        "- [ChromaDB](https://github.com/chroma-core/chroma) - AI-native open-source embedding database\n",
        "- [ArXiv API](https://arxiv.org/help/api) - Interface for accessing ArXiv papers\n",
        "\n",
        "---\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "**üåü Thank you for using AI Research Assistant! üåü**\n",
        "\n",
        "*If you find this project helpful, please consider giving it a star on GitHub!*\n",
        "\n",
        "[![GitHub stars](https://img.shields.io/github/stars/yourusername/ai-research-assistant?style=social)](https://github.com/yourusername/ai-research-assistant/stargazers)\n",
        "\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}